{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8592343-ab18-4638-b00d-d0e128539e23",
   "metadata": {},
   "source": [
    "# Pitch Outcome Transfer \n",
    "- using the pitch clusters from 3.1, train a general model\n",
    "- can then use these as initial weights for models, which hopefully helps with low AB players.\n",
    "## Todo:\n",
    "- write query to get training data for each cluster\n",
    "- train model using all of this data\n",
    "- save weights\n",
    "- write script to load the initial weights based on new batters cluster\n",
    "- train model using this\n",
    "- compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3280a0db-0f1c-4af0-a7ff-40436dc758b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:22:31,147 - src.features.build_features - INFO - Loading dataset for cluster 8\n",
      "2024-05-07 16:22:37,676 - src.features.build_features - INFO - Data successfully queried/transformed for cluster 8\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "#vladdy: 665489\n",
    "#soto: 665742\n",
    "#schneider 676914\n",
    "\n",
    "#get test set\n",
    "from src.features import build_features as f\n",
    "reload(f)\n",
    "#train_set, val_set, num_classes, num_features, encoder = f.get_pitch_outcome_dataset(665742)\n",
    "train_set, val_set, num_classes, num_features, encoder = f.get_pitch_outcome_dataset_general(8, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4e560a7-e31a-48d4-979a-ae524c9a9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09457801-bacf-4c1b-9b74-ac5074c78b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchOutcome(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(PitchOutcome, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.l3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "daa997d7-6912-4f05-8bf9-1538f208c0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loglik: -46148.9570 loss: 0.8863 val_accuracy: 60%: 100%|█████████████████████████| 50/50 [04:57<00:00,  5.96s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "input_size = num_features\n",
    "num_classes = num_classes\n",
    "\n",
    "model = PitchOutcome(input_size, num_classes)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = lr_scheduler.LinearLR(optim, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "\n",
    "val_accuracies, val_losses, train_losses, logliks = [], [], [], []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "for epoch in (t := trange(num_epochs)):\n",
    "\n",
    "    #train model\n",
    "    model.train()\n",
    "    running_loss = 0    \n",
    "    for features, labels in train_set:\n",
    "\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        #zero grads\n",
    "        optim.zero_grad()\n",
    "        #forward + backward + optimize\n",
    "        outputs = model(features)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #track loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    running_loss /= len(train_set)\n",
    "    train_losses.append(running_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    #validate model\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_probs = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_set:\n",
    "            #one_hot_labels = labels\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            #track loglik\n",
    "            predicted_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())  # Convert to probabilities\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            #convert one hot back to label\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            #print(predicted.shape, labels.shape, labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_set)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(100 * correct//total)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    predicted_probs = np.array(predicted_probs)\n",
    "    log_predicted_probs = np.log(predicted_probs + 1e-10)\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    #compute loglik for model\n",
    "    true_class_indices = np.argmax(true_labels, axis=1)\n",
    "    log_liks = log_predicted_probs[np.arange(len(true_class_indices)), true_class_indices]\n",
    "    total_log_lik = np.sum(log_liks)\n",
    "    logliks.append(total_log_lik)\n",
    "    \n",
    "    t.set_description(f'val_loglik: {total_log_lik:.4f} loss: {running_loss:.4f} val_accuracy: {100 * correct//total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e7531-ec49-4cf6-8aa6-fa786a8443b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba2c705c-920f-4fd4-aa3f-301032ca9e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        0.6137584 0.8662361 0.5982355 1.       ]\n",
      "ML Pitch Outcome Model LogLik: -46148.95\n",
      "Standard Categorical Distribution LogLik: -68266.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-46148.953, -68266.27)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pitch_outcome_loglik(model, train_set, val_set):\n",
    "\n",
    "    train_true_labels = []\n",
    "    predicted_probs = []\n",
    "    true_labels = []\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    # Get predicted probabilities and true labels\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_set:\n",
    "            features, labels = features, labels\n",
    "            outputs = model(features)\n",
    "            predicted_probs.extend(torch.softmax(outputs, dim=1).numpy())  # Convert to probabilities\n",
    "            true_labels.extend(labels.numpy())\n",
    "            train_true_labels.extend(labels.numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    predicted_probs = np.array(predicted_probs)\n",
    "    print(np.max(predicted_probs,axis=0))\n",
    "    log_predicted_probs = np.log(predicted_probs +1e-10)\n",
    "    true_labels = np.array(true_labels)\n",
    "    train_true_labels = np.array(train_true_labels)\n",
    "    \n",
    "    #compute loglik for model\n",
    "    true_class_indices = np.argmax(true_labels, axis=1)\n",
    "    log_liks = log_predicted_probs[np.arange(len(true_class_indices)), true_class_indices]\n",
    "    total_log_lik = np.sum(log_liks)\n",
    "\n",
    "    #------------- val loglik is better than multinomail ----------\n",
    "    #compute loglik for multinomial model\n",
    "    \n",
    "    #computes proportion of times a certain value showed up\n",
    "    categorical_p_est = np.mean(train_true_labels, axis=0)\n",
    "    log_predicted_probs = np.log(categorical_p_est)\n",
    "    categorical_dist_logliks = log_predicted_probs[true_class_indices]\n",
    "    categorical_log_lik = np.sum(categorical_dist_logliks)\n",
    "\n",
    "    print(f'ML Pitch Outcome Model LogLik: {total_log_lik:.2f}\\nStandard Categorical Distribution LogLik: {categorical_log_lik:.2f}')\n",
    "\n",
    "    assert(total_log_lik > categorical_log_lik)\n",
    "    \n",
    "    return total_log_lik, categorical_log_lik\n",
    "\n",
    "\n",
    "pitch_outcome_loglik(model, train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee0316e2-c787-4219-964c-c42c76212d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6925834594370402"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model which doesn't account for batter stance:\n",
    "#loglik: -77581.53 vs -112017.59\n",
    "no_stance = -77581.53 / -112017.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8467e8c1-13e5-4660-9aaa-c8aa91c16de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['ball'],\n",
       "       ['foul'],\n",
       "       ['hit_by_pitch'],\n",
       "       ['hit_into_play'],\n",
       "       ['strike']], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a:=torch.eye(5))\n",
    "encoder['pitch_outcome'].inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a7a93f7-27eb-426e-bb0f-55993e0523fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/pitch_outcome/cluster_models/cluster_8_bats_L.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
