{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2f4c14-39f7-454f-923e-19398f02ad9e",
   "metadata": {},
   "source": [
    "# Generate a Pitch\n",
    " - Given the current pitcher, game state, num pitches thrown, opposing batter characteristics, and pitcher characteristics\n",
    " - What will the next pitch look like?\n",
    "## Answers 2 questions:\n",
    " - Next pitch type to be thrown?\n",
    " - What are the characteristics of the pitch (speed, release pos, zone, etc.)?\n",
    " - Will be used as input to the batter\n",
    "## Potential Difficulties:\n",
    " - How do you quantify the change in pitch type distribution based on opposing batters statistics?\n",
    " - How do you factor the correlation between pitch characteristics like release pos, etc. to generate realistic pithces?\n",
    " - How do you adjust factors based on the opposing batter's zone?\n",
    " - How do you adjust based on pitch sequencing?\n",
    "## TODO:\n",
    " - Write script to get features (formatted with labels in torch)\n",
    " - Hyperparameter optimization\n",
    " - Figure out how to solve small sample.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d4f26-221b-4d61-a676-53b65be6393f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae0b2f4-7e7f-4d0c-9d8a-61799a514bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Step [0/32], Discriminator Loss: 1.3925, Generator Loss: 0.7373\n",
      "Generated Pitch: [[-0.46649253 -0.0610469  -0.20583172 -0.4319409   0.1633176   0.27569598\n",
      "  -0.2807712  -0.10416228 -0.09181148 -0.01386006  0.32783017 -0.05387577\n",
      "   0.05743945]]\n",
      "Epoch [1/10], Step [0/32], Discriminator Loss: 1.3346, Generator Loss: 0.6634\n",
      "Generated Pitch: [[-0.5472274   0.2023207  -0.00588593 -0.16892159 -0.09596489  0.34547776\n",
      "   0.04078218 -0.17209241  0.03756853 -0.38079143  0.4800952   0.14270556\n",
      "   0.1917249 ]]\n",
      "Epoch [2/10], Step [0/32], Discriminator Loss: 1.2490, Generator Loss: 0.7029\n",
      "Generated Pitch: [[ 0.13217169  0.21097228  0.74631685  0.4142247  -0.7970775  -0.04869391\n",
      "   0.27592966  0.28983235  0.19589043  0.04534231  0.17362332  0.47454736\n",
      "  -0.04931539]]\n",
      "Epoch [3/10], Step [0/32], Discriminator Loss: 1.3172, Generator Loss: 0.6337\n",
      "Generated Pitch: [[ 0.9342575  -0.4202156   1.4209844   1.1519558  -0.842765   -0.84077966\n",
      "  -0.09117113  0.5022152   0.37016445  0.9589467  -0.50420123  0.4062837\n",
      "  -0.7907197 ]]\n",
      "Epoch [4/10], Step [0/32], Discriminator Loss: 1.1845, Generator Loss: 0.7533\n",
      "Generated Pitch: [[ 1.3795893  -1.131853    0.42247826  0.6275771   0.18592782 -0.96375483\n",
      "  -1.0640956  -0.24637721 -0.03114375  1.112378   -0.8727453  -0.5730973\n",
      "  -1.2942532 ]]\n",
      "Epoch [5/10], Step [0/32], Discriminator Loss: 1.0349, Generator Loss: 0.8221\n",
      "Generated Pitch: [[ 0.5083192  -1.3364346  -1.0797852  -0.5333773   1.1308709  -0.26599503\n",
      "  -1.239596   -1.256691   -0.33885822  0.29870886 -0.27432704 -1.4520854\n",
      "  -0.6919225 ]]\n",
      "Epoch [6/10], Step [0/32], Discriminator Loss: 1.1794, Generator Loss: 0.6840\n",
      "Generated Pitch: [[-0.87428766 -0.3881262  -2.5811825  -1.929763    1.6269243   0.5689964\n",
      "  -0.01429383 -2.004362    0.6982043  -0.9985949   0.8684654  -0.8902125\n",
      "   0.3935318 ]]\n",
      "Epoch [7/10], Step [0/32], Discriminator Loss: 1.3902, Generator Loss: 0.5361\n",
      "Generated Pitch: [[-2.1791131   1.0270579  -2.9270523  -2.5114858   0.36728555  1.3700705\n",
      "   1.9439412  -0.50121063  2.108383   -2.6153066   1.7079799   1.2716057\n",
      "   1.47343   ]]\n",
      "Epoch [8/10], Step [0/32], Discriminator Loss: 0.9544, Generator Loss: 1.4002\n",
      "Generated Pitch: [[-1.6434101   1.6766677  -1.0321203  -0.8139714  -1.232442    0.26768762\n",
      "   2.9606109   1.4158815   1.1761093  -2.034747    0.60952175  2.6922364\n",
      "   0.7824852 ]]\n",
      "Epoch [9/10], Step [0/32], Discriminator Loss: 0.9470, Generator Loss: 1.3577\n",
      "Generated Pitch: [[-0.17567338  1.7106409   0.7383603   0.53230244 -2.01621    -1.0004884\n",
      "   2.164657    2.483411   -0.47203988 -0.3773834  -0.40368545  2.883182\n",
      "  -0.5526122 ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "\n",
    "# Define the Generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, conditioning_size, output_size, hidden_size=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.conditioning_size = conditioning_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size + conditioning_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, z, c):\n",
    "        x = torch.cat([z, c], dim=1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the Discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, conditioning_size, hidden_size=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.conditioning_size = conditioning_size\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size + conditioning_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x, c):\n",
    "        x = torch.cat([x, c], dim=1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the GAN model\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "    def forward(self, z, c):\n",
    "        fake_pitches = self.generator(z, c)\n",
    "        return fake_pitches\n",
    "\n",
    "# Generate random noise vector\n",
    "def generate_noise(batch_size, noise_size):\n",
    "    return torch.randn(batch_size, noise_size)\n",
    "\n",
    "# Generate fake conditioning variables (e.g., game factors)\n",
    "def generate_conditioning(batch_size, conditioning_size):\n",
    "    return torch.randn(batch_size, conditioning_size)\n",
    "\n",
    "# Main function for training the GAN\n",
    "def train_gan(gan, dataloader, num_epochs, batch_size, noise_size, conditioning_size):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    d_optimizer = optim.Adam(gan.discriminator.parameters(), lr=0.0002)\n",
    "    g_optimizer = optim.Adam(gan.generator.parameters(), lr=0.0002)\n",
    "    fixed_noise = generate_noise(1, noise_size)\n",
    "    fixed_conditioning = generate_conditioning(1, conditioning_size)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_data, conditioning) in enumerate(dataloader):\n",
    "            batch_size = real_data.size(0)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            real_data = real_data.view(-1, gan.generator.output_size)\n",
    "            real_data = real_data.to(device)\n",
    "            conditioning = conditioning.to(device)\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            d_optimizer.zero_grad()\n",
    "            real_outputs = gan.discriminator(real_data, conditioning)\n",
    "            d_loss_real = criterion(real_outputs, real_labels)\n",
    "            \n",
    "            noise = generate_noise(batch_size, noise_size).to(device)\n",
    "            fake_pitches = gan.generator(noise, conditioning)\n",
    "            fake_outputs = gan.discriminator(fake_pitches.detach(), conditioning)\n",
    "            d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "            \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_outputs = gan.discriminator(fake_pitches, conditioning)\n",
    "            g_loss = criterion(fake_outputs, real_labels)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], \"\n",
    "                      f\"Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
    "                \n",
    "        # Generate sample pitch at end of each epoch\n",
    "        with torch.no_grad():\n",
    "            fake_pitch = gan.generator(fixed_noise, fixed_conditioning).cpu().detach().numpy()\n",
    "            print(\"Generated Pitch:\", fake_pitch)\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define hyperparameters\n",
    "    batch_size = 32\n",
    "    noise_size = 100\n",
    "    conditioning_size = 10\n",
    "    input_size = 100\n",
    "    output_size = 13  \n",
    "    hidden_size = 128\n",
    "    num_epochs = 10\n",
    "    \n",
    "    # Dummy dataset\n",
    "    pitches = torch.randn(1000, output_size)  # Dummy pitch data\n",
    "    conditioning_vars = torch.randn(1000, conditioning_size)  # Dummy conditioning variables\n",
    "    \n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataset = TensorDataset(pitches, conditioning_vars)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Create GAN model\n",
    "    generator = Generator(input_size, conditioning_size, output_size, hidden_size)\n",
    "    discriminator = Discriminator(output_size, conditioning_size, hidden_size)\n",
    "    gan = GAN(generator, discriminator)\n",
    "    \n",
    "    # Training the GAN\n",
    "    train_gan(gan, dataloader, num_epochs, batch_size, noise_size, conditioning_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35dad9ea-3507-4078-8132-21bf1d18d71f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'generator.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Load the trained GAN model (generator)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Replace \"generator\" with your trained generator model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     generator \u001b[38;5;241m=\u001b[39m Generator(input_size, conditioning_size, output_size, hidden_size)\n\u001b[0;32m---> 19\u001b[0m     generator\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerator.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Load trained weights\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Define hyperparameters\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     noise_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlb/lib/python3.12/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/mlb/lib/python3.12/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlb/lib/python3.12/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'generator.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Function to generate pitches using the trained GAN model\n",
    "def generate_pitch(generator, noise_size, conditioning):\n",
    "    # Generate random noise vector\n",
    "    noise = torch.randn(1, noise_size)\n",
    "    \n",
    "    # Generate pitch using generator\n",
    "    with torch.no_grad():\n",
    "        generated_pitch = generator(noise, conditioning)\n",
    "    \n",
    "    return generated_pitch\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained GAN model (generator)\n",
    "    # Replace \"generator\" with your trained generator model\n",
    "    generator = Generator(input_size, conditioning_size, output_size, hidden_size)\n",
    "    generator.load_state_dict(torch.load(\"generator.pth\"))  # Load trained weights\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    noise_size = 100\n",
    "    conditioning_size = 10\n",
    "    \n",
    "    # Define conditioning variables based on game factors\n",
    "    # Replace this with actual game factors from your MLB simulation model\n",
    "    conditioning = torch.randn(1, conditioning_size)\n",
    "    \n",
    "    # Generate pitch\n",
    "    generated_pitch = generate_pitch(generator, noise_size, conditioning)\n",
    "    \n",
    "    # Print generated pitch\n",
    "    print(\"Generated Pitch:\", generated_pitch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
